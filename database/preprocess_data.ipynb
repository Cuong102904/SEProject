{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imdb import IMDb\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('E:/DEV/SE/database/tmdb_5000_movies.csv')\n",
    "\n",
    "# Select the specific columns\n",
    "selected_columns = [\n",
    "    'id_film', 'title', 'overview', 'original_language', \n",
    "    'release_date', 'status', 'tagline', 'runtime', \n",
    "    'revenue', 'vote_average'\n",
    "]\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Initializing the IMDb class\n",
    "ia = IMDb()\n",
    "\n",
    "# Function to get the movie poster URL\n",
    "def getMoviePosterUrl(title, counter):\n",
    "    try:\n",
    "        # Stop if we have already reached 100 successful URLs\n",
    "        if counter[0] >= 50:\n",
    "            return None\n",
    "\n",
    "        # Searching for the movie using its title\n",
    "        movies = ia.search_movie(title)\n",
    "        \n",
    "        # If the movie is found\n",
    "        if movies:\n",
    "            # Getting the details of the first movie in the search results\n",
    "            movie = movies[0]\n",
    "            movieDetails = ia.get_movie(movie.movieID)\n",
    "            \n",
    "            # Getting the URL of the movie poster\n",
    "            poster_url = movieDetails.get('full-size cover url')\n",
    "            \n",
    "            if poster_url:\n",
    "                counter[0] += 1  # Increment the counter\n",
    "                return poster_url\n",
    "        \n",
    "        # Returning None if the movie is not found or no poster URL\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching poster for {title}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Counter to keep track of the number of successful URLs\n",
    "successful_url_counter = [0]\n",
    "\n",
    "# Add a new column for the movie poster URL\n",
    "df_selected['poster_url'] = df_selected['title'].apply(lambda title: getMoviePosterUrl(title, successful_url_counter))\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "df_selected.to_csv('movie_with_poster_url.csv', index=False)\n",
    "\n",
    "logging.info('Selected columns saved to movie_with_poster_url.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the cast\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV và chọn cột 'genres' và 'id_film'\n",
    "with open('E:/DEV/SE/database/tmdb_5000_credits.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = [{'cast': row['cast'], 'movie_id': row['movie_id']} for row in reader]\n",
    "\n",
    "# Tạo danh sách các ô\n",
    "cells = []\n",
    "\n",
    "# Lặp qua từng block dữ liệu và thêm id_film vào từng từ điển\n",
    "for row in data:\n",
    "    block = json.loads(row['cast'])\n",
    "    for item in block:\n",
    "        item['movie_id'] = row['movie_id']  # Thêm id_film từ dữ liệu đã đọc từ tệp CSV\n",
    "        cells.append([item])  # Thêm từ điển vào danh sách các ô\n",
    "\n",
    "# Tên của file CSV\n",
    "csv_file = \"E:/DEV/SE/database/cast.csv\"\n",
    "\n",
    "# Ghi dữ liệu vào file CSV\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['cast_id', 'character', 'credit_id','gender','id','name','order','movie_id'])  # Ghi header của CSV\n",
    "    for cell in cells:\n",
    "        for item in cell:\n",
    "            writer.writerow([item['cast_id'], item['character'], item['credit_id'],item['gender'],item['id'],item['name'],item['order'],item['movie_id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('E:\\DEV\\SE\\database\\cast.csv')\n",
    "\n",
    "# Remove duplicate values based on a specific column\n",
    "# Replace 'column_name' with the name of the column you want to check for duplicates\n",
    "df_unique = df.drop_duplicates(subset='id')\n",
    "\n",
    "# Save the cleaned DataFrame back to a new CSV file\n",
    "df_unique.to_csv('cast1.csv', index=False)\n",
    "\n",
    "print('Duplicates removed and saved to output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the schedule table\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize variables\n",
    "start_date = datetime(2024, 3, 6)\n",
    "initial_time = datetime.strptime(\"08:20\", \"%H:%M\")\n",
    "end_time = datetime.strptime(\"22:20\", \"%H:%M\")\n",
    "\n",
    "# Create lists to store values\n",
    "screen_dates = []\n",
    "start_times = []\n",
    "\n",
    "# Generate values\n",
    "while len(screen_dates) < 500:\n",
    "    current_time = initial_time\n",
    "    while current_time <= end_time:\n",
    "        if len(screen_dates) >= 500:\n",
    "            break\n",
    "        screen_dates.append(start_date.strftime(\"%Y-%m-%d\"))\n",
    "        start_times.append(current_time.strftime(\"%H:%M\"))\n",
    "        current_time += timedelta(hours=2)\n",
    "    start_date += timedelta(days=1)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"screen_date\": screen_dates,\n",
    "    \"start_time\": start_times\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('schedule.csv', index=False)\n",
    "\n",
    "print('CSV file created successfully with 500 rows.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_join_gerne table \n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV và chọn cột 'genres' và 'id_film'\n",
    "with open('E:/DEV/SE/database/tmdb_5000_movies.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = [{'genres': row['genres'], 'id_film': row['id_film']} for row in reader]\n",
    "\n",
    "# Tạo danh sách các ô\n",
    "cells = []\n",
    "\n",
    "# Lặp qua từng block dữ liệu và thêm id_film vào từng từ điển\n",
    "for row in data:\n",
    "    block = json.loads(row['genres'])\n",
    "    for item in block:\n",
    "        item['id_film'] = row['id_film']  # Thêm id_film từ dữ liệu đã đọc từ tệp CSV\n",
    "        cells.append([item])  # Thêm từ điển vào danh sách các ô\n",
    "\n",
    "# Tên của file CSV\n",
    "csv_file = \"E:/DEV/SE/database/output4.csv\"\n",
    "\n",
    "# Ghi dữ liệu vào file CSV\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['id', 'name', 'id_film'])  # Ghi header của CSV\n",
    "    for cell in cells:\n",
    "        for item in cell:\n",
    "            writer.writerow([item['id'], item['name'], item['id_film']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
